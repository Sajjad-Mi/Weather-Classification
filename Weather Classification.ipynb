{"cells":[{"cell_type":"markdown","metadata":{"id":"Wy0FJAWa3x_S"},"source":["# **Download Dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bTTslhDMxtEy"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_564siMezmFR"},"outputs":[],"source":["import os\n","os.environ['KAGGLE_CONFIG_DIR'] = \"/content/drive/MyDrive/kaggle\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tKXfMZbMz1kN"},"outputs":[],"source":["%cd /content/drive/MyDrive/DL/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SzGPOCn90oZ-"},"outputs":[],"source":["!kaggle datasets download -d pratik2901/multiclass-weather-dataset --unzip"]},{"cell_type":"markdown","metadata":{"id":"TOVCio9E4G3H"},"source":["# **Import**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r_oPFkFWWDNw"},"outputs":[],"source":["import cv2\n","import numpy as np\n","import numpy\n","from matplotlib import pyplot\n","from PIL import Image \n","from sklearn.model_selection import train_test_split\n","from keras.utils import np_utils\n","from sklearn.preprocessing import LabelEncoder\n","import tensorflow as tf\n","from sklearn.metrics import classification_report\n","import matplotlib.pyplot as plt\n","from keras import Sequential\n","from keras.layers import Dense, Conv2D, Flatten, BatchNormalization, Dropout, Input, MaxPooling2D, AveragePooling2D, Activation, add\n","from keras.layers.merge import concatenate\n","from keras.utils.vis_utils import plot_model\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import KFold\n","from numpy import mean\n","from numpy import std\n","from sklearn.model_selection import cross_val_score"]},{"cell_type":"markdown","metadata":{"id":"ZsfuGCc3dkb8"},"source":["# **Ready Dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uDWd4s2J2upr"},"outputs":[],"source":["\n","images = []\n","labels = []\n","resize_images = []\n","convert = {'Cloudy':0, 'Rain':1, 'Shine':2, 'Sunrise':3}\n","\n","path = \"/content/drive/MyDrive/DL/Multi-class Weather Dataset\"\n","print(os.listdir(path))\n","for filename in os.listdir(path):\n","  for filename1 in os.listdir(path+'/'+filename):\n","      img = cv2.imread(path+'/'+filename+'/'+filename1)\n","      if img is not None:\n","          images.append(img)\n","          labels.append(convert[filename])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_RYwk-0bIreg"},"outputs":[],"source":["# Data distribution\n","num_distr = np.zeros(4, dtype=int)\n","labels_name = ['Cloudy', 'Rain', 'Shine', 'Sunrise']\n","for i in range(len(labels)):\n","  num_distr[labels[i]]+=1\n","\n","print(f'Number of data {len(labels)}')\n","\n","for i in range(len(labels_name)):\n","  print(f'{num_distr[i]} of the datasets are {labels_name[i]}')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7bZP03Pg2yMx"},"outputs":[],"source":["#convert images to PLI image and resize images\n","for i in range(len(images)):\n","  img = Image.fromarray(images[i], \"RGB\")\n","  images[i] = img.resize((80, 80))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c2S7sa56t7co"},"outputs":[],"source":["#convert back images from PLI to np array\n","for i in range(len(images)):\n","  img = np.array(images[i])\n","  images[i] = img\n","images = np.array(images)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3xs_rbM1Sabk"},"outputs":[],"source":["#convert lables to hot encoding\n","encoder = LabelEncoder()\n","encoder.fit(labels)\n","encoded_y = encoder.transform(labels)\n","ll = np_utils.to_categorical(encoded_y)\n"]},{"cell_type":"markdown","metadata":{"id":"Fr9flItYd21-"},"source":["# **Split Data**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wOvOEyjduSIm"},"outputs":[],"source":["x_train, x_test, y_train, y_test = train_test_split(images, ll, test_size=0.2, random_state=30)"]},{"cell_type":"markdown","metadata":{"id":"Ta9hQkI-eaaq"},"source":["\n","# **Build Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wP48KBSLugV9"},"outputs":[],"source":["opt = tf.keras.optimizers.Adam(learning_rate=0.001) \n","\n","model = Sequential()\n","model.add(Input(shape = images[0].shape))\n","model.add(Conv2D(6, padding=\"valid\", strides=1,  dilation_rate=1, kernel_size=5, activation='tanh'))\n","model.add(AveragePooling2D(pool_size=2, strides=2))\n","model.add(Conv2D(8, padding=\"valid\", strides=1,  dilation_rate=1, kernel_size=5, activation='tanh'))\n","model.add(AveragePooling2D(pool_size=2, strides=2))\n","#model.add(Dropout(0.3))\n","model.add(Flatten())\n","model.add(Dense(15, activation='relu'))\n","#model.add(Dense(8, activation='elu'))\n","#model.add(Dropout(0.3))\n","model.add(Dense(8, activation='elu'))\n","#model.add(Dropout(0.3))\n","model.add(Dense(4, activation='softmax'))\n","model.compile(loss=\"categorical_crossentropy\",\n","              optimizer = opt,\n","              metrics=['accuracy'])\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"gxw7ROGOfPvB"},"source":["\n","# **Build ResNet Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"okwwe9uxbQ7O"},"outputs":[],"source":["from keras.models import Model\n","\n","opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n","def residual_module(layer_in, n_filters):\n","\n","\tmerge_input = layer_in\n","\t# check if the number of filters needs to be increase\n","\n","\tif layer_in.shape[-1] != n_filters:\n","\t\tmerge_input = Conv2D(n_filters, 1, padding='same', activation='relu', kernel_initializer='he_normal')(layer_in)\n","\tconv1 = Conv2D(n_filters, 3, padding='same', activation='relu', kernel_initializer='he_normal')(layer_in)\n","\tconv2 = Conv2D(n_filters, 3, padding='same', activation='linear', kernel_initializer='he_normal')(conv1)\n","\tlayer_out = add([conv2, merge_input])\n","\tlayer_out = Activation('relu')(layer_out)\n","\treturn layer_out\n","input_layer = Input(shape = images[0].shape)\n","layer = Conv2D(5, padding=\"valid\", strides=1,  dilation_rate=2, kernel_size=3, activation='tanh')(input_layer)\n","layer = MaxPooling2D(pool_size=2, strides=2)(layer)\n","layer = residual_module(layer, 16)\n","layer = residual_module(layer, 16)\n","layer = residual_module(layer, 32)\n","layer = residual_module(layer, 32)\n","layer = Flatten()(layer)\n","\n","layer = Dense(4, activation='softmax')(layer)\n","\n","model = Model(inputs=input_layer, outputs=layer)\n","\n","model.compile(loss=\"categorical_crossentropy\",\n","              optimizer = opt,\n","              metrics=['accuracy'])\n","plot_model(model)"]},{"cell_type":"markdown","metadata":{"id":"QEaZqsI7eECF"},"source":["# **Build Inception Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Q0AMTFkxbX2"},"outputs":[],"source":["from keras.models import Model\n","opt = tf.keras.optimizers.Adam(learning_rate=0.001) \n","\n","def inception_module(layer_in, f1, f2, f3):\n","\tconv1 = Conv2D(f1, kernel_size=5, padding='same', activation='relu')(layer_in)\n","\tconv3 = Conv2D(f2, kernel_size=5, padding='same', activation='relu')(layer_in)\n","\tconv5 = Conv2D(f3, kernel_size=5, padding='same', activation='relu')(layer_in)\n","\tpool = MaxPooling2D(pool_size=3, strides=1, padding='same')(layer_in)\n","\tlayer_out = concatenate([conv1, conv3, conv5, pool], axis=-1)\n","\treturn layer_out\n","\n","input_layer = Input(shape = images[0].shape)\n","layer = Conv2D(5, padding=\"valid\", strides=1,  dilation_rate=1, kernel_size=3, activation='tanh')(input_layer)\n","layer = MaxPooling2D(pool_size=2, strides=2)(layer)\n","layer = Conv2D(5, padding=\"valid\", strides=1,  dilation_rate=1, kernel_size=3, activation='tanh')(layer)\n","layer = MaxPooling2D(pool_size=2, strides=2)(layer)\n","layer = Conv2D(5, padding=\"valid\", strides=1,  dilation_rate=1, kernel_size=3, activation='tanh')(layer)\n","layer = MaxPooling2D(pool_size=2, strides=2)(layer)\n","layer = inception_module(layer,  16, 16, 16)\n","#layer = inception_module(layer,  16, 32, 16)\n","#layer = inception_module(layer,  16, 16, 16)\n","layer = Flatten()(layer)\n","layer = Dense(4, activation='softmax')(layer)\n","model = Model(inputs=input_layer, outputs=layer)\n","\n","model.compile(loss=\"categorical_crossentropy\",\n","              optimizer = opt,\n","              metrics=['accuracy'])\n","#plot_model(model)\n"]},{"cell_type":"markdown","metadata":{"id":"W4Jj5dOqxQF8"},"source":["\n","# **Train Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J5eVpBGrxlIg"},"outputs":[],"source":["history = model.fit(x_train, y_train, epochs=50, validation_split=0.2)"]},{"cell_type":"markdown","metadata":{"id":"DlMmPOI-Bjx3"},"source":["# Evaluate train and test set "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mQxkC1L6AXI_"},"outputs":[],"source":["loss, accuracy = model.evaluate(x_train, y_train)\n","print('Accuracy of train set: %.2f' % (accuracy*100))\n","print('Loss of train set: %.3f' % (loss))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qsk0lDz3Asne"},"outputs":[],"source":["loss, accuracy = model.evaluate(x_test, y_test)\n","print('Accuracy of test set: %.2f' % (accuracy*100))\n","print('Loss of test set: %.3f' % (loss))"]},{"cell_type":"markdown","metadata":{"id":"KsTJjOh6x8dr"},"source":["# Plot"]},{"cell_type":"markdown","metadata":{"id":"mIJg0_XK1u-b"},"source":["*Plot* loss and accuracy of train set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gexl4x1P4NpA"},"outputs":[],"source":["history = history.history"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xYZg2r5oyDkG"},"outputs":[],"source":["plt.plot(history['accuracy'])\n","plt.xlabel('Epoch')\n","plt.ylabel('accuracy')\n","plt.show()\n","plt.plot(history['loss'], 'green')\n","plt.xlabel('Epoch')\n","plt.ylabel('loss')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ZsUgIE491YVd"},"source":["*Plot* loss and accuracy of validation set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lgrOuuPm2PF8"},"outputs":[],"source":["plt.plot(history['val_accuracy'])\n","plt.xlabel('Epoch')\n","plt.ylabel('accuracy')\n","plt.show()\n","plt.plot(history['val_loss'], 'green')\n","plt.xlabel('Epoch')\n","plt.ylabel('loss')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"HUoWPWvFxKiF"},"source":["comparing loss of train and validation set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IiCGvPiK4HfW"},"outputs":[],"source":["#plt.figure(figsize=(12, 20))\n","\n","plt.plot(history['loss'], color='blue')\n","plt.plot(history['val_loss'], color='green')\n","plt.title('Model Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend(['Train', 'Val.'])\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"3NOgpu1Fwt8O"},"source":["comparing accuracy of train and validation set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qVJ8HyJi4obk"},"outputs":[],"source":["\n","plt.plot(history['accuracy'], color='blue')\n","plt.plot(history['val_accuracy'], color='green')\n","plt.title('Model Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend(['Train', 'Val.'])\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"jrNlRF8rhZwG"},"source":["# **k fold cross validation**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TCb9VZ5DlyEc"},"outputs":[],"source":["kfold = KFold(n_splits=5, shuffle=True)\n","cvscores = []\n","scores = []\n","print(kfold.split(images, ll))\n","for train, test in kfold.split(images, ll):\n","  model.fit(images[train], ll[train], epochs=50)\n","  score = model.evaluate(images[test], ll[test], verbose=0)\n","  scores.append(score)\n","  cvscores.append(score * 100)\n","  print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))\n","\n","#print loss and accuracy for each training\n","for i in range(len(cvscores)):\n","  print(\"%s: %.3f\" % (model.metrics_names[0], scores[i][0]))\n","  print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[i][1]*100))\n","\n","  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p6vEufrX1zse"},"outputs":[],"source":["#find the predicted result\n","y_predict = model.predict(x_test)\n","y_predict_int = np.argmax(y_predict, axis=1)\n","#convert back from hot encoding for comparing with predicted result\n","y_true = np.argmax(y_test, axis = 1)\n","\n","print(classification_report(y_true, y_predict_int))"]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}